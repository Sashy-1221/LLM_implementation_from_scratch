{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T09:52:53.262333898Z",
     "start_time": "2026-01-17T09:52:53.237064628Z"
    }
   },
   "source": [
    "import torch\n",
    "from LLM_implementation.LLM_implementation import GPTModel\n",
    "from Token_utils import *\n",
    "import torch.nn.functional as F\n",
    "from Embedding.window import create_dataloader_v1"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T09:52:53.296601532Z",
     "start_time": "2026-01-17T09:52:53.283704210Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}"
   ],
   "id": "dded4278b3df4188",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T09:52:54.029443703Z",
     "start_time": "2026-01-17T09:52:53.318316218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ],
   "id": "59a3bc396645d15e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T09:52:54.047911230Z",
     "start_time": "2026-01-17T09:52:54.039224848Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "file_path = \"../Embedding/the-verdict.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text_data = file.read()"
   ],
   "id": "42840c294b491e0",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T09:52:54.071708851Z",
     "start_time": "2026-01-17T09:52:54.048938456Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ],
   "id": "d5b9497704abecbb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T09:52:54.100156190Z",
     "start_time": "2026-01-17T09:52:54.092146825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n"
   ],
   "id": "5d75ad252c347b47",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T09:52:54.107911796Z",
     "start_time": "2026-01-17T09:52:54.101188174Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "#\n",
    "# token_ids = generate_text_simple(\n",
    "#     model=model,\n",
    "#     idx=text_to_token_ids(start_context, tokenizer),\n",
    "#     max_new_tokens=10,\n",
    "#     context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    "# )\n",
    "#\n",
    "# print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ],
   "id": "1677dcb97517a981",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T09:52:54.116642891Z",
     "start_time": "2026-01-17T09:52:54.108604410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return total_loss / num_batches\n"
   ],
   "id": "39576bcc81df0ce6",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T09:52:54.125364328Z",
     "start_time": "2026-01-17T09:52:54.117489739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def calculate_loss(model, batch):\n",
    "    input_idx = batch[:, :-1]\n",
    "    target_idx = batch[:, 1:]\n",
    "    logits = model(input_idx)\n",
    "    loss = F.cross_entropy(logits.view(-1, logits.size(-1)), target_idx.reshape(-1))\n",
    "    return loss\n"
   ],
   "id": "3b3f9354527804c9",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T09:52:54.136437557Z",
     "start_time": "2026-01-17T09:52:54.126633732Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "torch.manual_seed(123)\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n"
   ],
   "id": "7b91bbeb58fbed1c",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T09:53:01.426011082Z",
     "start_time": "2026-01-17T09:52:54.137528399Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ],
   "id": "2b053f14c55ea733",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.98758347829183\n",
      "Validation loss: 10.98110580444336\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T09:53:01.442052319Z",
     "start_time": "2026-01-17T09:53:01.434186409Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    model.train()\n"
   ],
   "id": "8eedf2dbc90044f2",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T09:53:01.458465362Z",
     "start_time": "2026-01-17T09:53:01.443020535Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(\n",
    "        train_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_loss = calc_loss_loader(\n",
    "        val_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        model.train()\n",
    "    return train_loss, val_loss"
   ],
   "id": "afaace50be8c94cb",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T09:53:01.468990353Z",
     "start_time": "2026-01-17T09:53:01.459389870Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device,\n",
    "                      num_epochs, eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, \"\n",
    "                      f\"Val loss {val_loss:.3f}\")\n",
    "                generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n"
   ],
   "id": "c9b4ffd233b0e86b",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T10:02:59.562502225Z",
     "start_time": "2026-01-17T09:53:01.470678427Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")\n"
   ],
   "id": "4684e59dfb321c0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.781, Val loss 9.933\n",
      "Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,, the the,,,,,,,,,,,,,,,,,,,\n",
      "Ep 1 (Step 000005): Train loss 8.111, Val loss 8.339\n",
      "Every effort moves you, the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "Ep 2 (Step 000010): Train loss 6.661, Val loss 7.048\n",
      "Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,, the,,,,,,,,,,,,,,,,,,,,\n",
      "Ep 2 (Step 000015): Train loss 5.961, Val loss 6.616\n",
      "Every effort moves you, and, and,, and, and,,, and, and, and,, and,,,, and, and,, and,,,, and,, and,,, and, and,,, and, and\n",
      "Ep 3 (Step 000020): Train loss 5.726, Val loss 6.600\n",
      "Every effort moves you, and I had\"                                             \n",
      "Ep 3 (Step 000025): Train loss 5.201, Val loss 6.348\n",
      "Every effort moves you his! Gisburn. Gisburn to the picture.   \"I        \"I. \"I the of the--and it.  \"I was--III was the\n",
      "Ep 4 (Step 000030): Train loss 4.417, Val loss 6.278\n",
      "Every effort moves you, and I had been the picture. \"I was aI was a\", I had been--and, I had been to the picture. I had the picture. I had the picture to the picture. \"I he was a\n",
      "Ep 4 (Step 000035): Train loss 4.069, Val loss 6.226\n",
      "Every effort moves you know the                          \"I he had the donkey and I had the and I had the donkey and down the room, I had\n",
      "Ep 5 (Step 000040): Train loss 3.732, Val loss 6.160\n",
      "Every effort moves you know                        He laughed again, and he had the donkey and he had been his pictures of his pictures and down the room, and he\n",
      "Ep 6 (Step 000045): Train loss 2.850, Val loss 6.179\n",
      "Every effort moves you know it was not that the picture--I had the fact with the last--his, and I was--and here are the Riv, and I had been his head to have.             \n",
      "Ep 6 (Step 000050): Train loss 2.427, Val loss 6.141\n",
      "Every effort moves you know,\" was one of the picture.  I turned to the last word.        He laughed again, I had back his head to the donkey.  \"I didn't--the. \"I\n",
      "Ep 7 (Step 000055): Train loss 2.104, Val loss 6.134\n",
      "Every effort moves you know,\" was not that I felt as it was the fact with a little a. Gisburn's past!     \"I was back the head to the donkey.  \"I had the man of the hour. The\n",
      "Ep 7 (Step 000060): Train loss 1.882, Val loss 6.233\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with a little a flash that he _rose of the fact, the cigars you like.\"  He placed them at my elbow and as I had been the--because he had always _\n",
      "Ep 8 (Step 000065): Train loss 1.320, Val loss 6.238\n",
      "Every effort moves you know,\" was one of the picture for nothing--I told Mrs.  \"I was no great surprise to me to have to see a smile behind his pictures.  \"Oh, I saw that, and down, and I was.\n",
      "Ep 8 (Step 000070): Train loss 0.985, Val loss 6.242\n",
      "Every effort moves you know,\" was one of the axioms he had been the tips of a self-confident moustache, I felt to see a smile behind his close grayish beard--as if he had the donkey. \"strongest,\" as his\n",
      "Ep 9 (Step 000075): Train loss 0.717, Val loss 6.293\n",
      "Every effort moves you know,\" was one of my hostess was \"interesting\": on that point I could have given Miss Croft the fact, had been to the display of his close grayish beard--as if he had the donkey. \"strongest,\" as his\n",
      "Ep 9 (Step 000080): Train loss 0.541, Val loss 6.393\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back the window-curtains, I had the donkey. \"There were days when I\n",
      "Ep 10 (Step 000085): Train loss 0.391, Val loss 6.452\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back the window-curtains, as I turned, my eye fell on a small picture\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T10:13:31.893103034Z",
     "start_time": "2026-01-17T10:13:31.870541514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import torch\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    if torch.is_tensor(epochs_seen):\n",
    "        epochs_seen = epochs_seen.cpu().tolist()\n",
    "    if torch.is_tensor(tokens_seen):\n",
    "        tokens_seen = tokens_seen.cpu().tolist()\n",
    "    if torch.is_tensor(train_losses):\n",
    "        train_losses = train_losses.cpu().tolist()\n",
    "    if torch.is_tensor(val_losses):\n",
    "        val_losses = val_losses.cpu().tolist()\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(\n",
    "        epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\"\n",
    "    )\n",
    "\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n"
   ],
   "id": "8e03e1edb0d6c7a4",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "import numpy",
   "id": "75f8311f50c52a6e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T10:13:36.837009670Z",
     "start_time": "2026-01-17T10:13:36.704263239Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ],
   "id": "531922f52dba32d4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " continued in temperature_testing and created the following function by combining temperature and top_k sampling",
   "id": "fac3d2ef57112fff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T10:22:12.413702208Z",
     "start_time": "2026-01-17T10:22:12.368755669Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float('-inf')).to(logits.device), logits)\n",
    "\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "\n",
    "        if idx_next == eos_id:\n",
    "            break\n",
    "\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "    return idx\n"
   ],
   "id": "2e53f8f9eb0cf7d0",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T10:22:14.743387554Z",
     "start_time": "2026-01-17T10:22:14.035957859Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# testing the output of the function\n",
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ],
   "id": "e346593764be04e8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves youlit terrace.\n",
      "\n",
      "\n",
      "\n",
      "\" he said deprecating laugh\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "saving the weights and checkpointing (for reference)",
   "id": "75960e750951f3f6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.save(model.state_dict(), \"model.pth\")",
   "id": "3e27533725492dcb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(torch.load(\"model.pth\", map_location=device))\n",
    "model.eval()"
   ],
   "id": "98a72445878d16a6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "torch.save({\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    },\n",
    "    \"model_and_optimizer.pth\"\n",
    ")"
   ],
   "id": "6333931111a6dbbe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "checkpoint = torch.load(\"model_and_optimizer.pth\", map_location=device)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train();"
   ],
   "id": "5b80f142e211bb50"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# importing weights from openAI gpt 2",
   "id": "f68e0891e951f818"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T10:26:04.982628477Z",
     "start_time": "2026-01-17T10:26:04.508858357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import urllib.request\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/\"\n",
    "    \"LLMs-from-scratch/main/ch05/\"\n",
    "    \"01_main-chapter-code/gpt_download.py\"\n",
    ")\n",
    "filename = url.split('/')[-1]\n",
    "urllib.request.urlretrieve(url, filename)"
   ],
   "id": "d00e104d94f44e89",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gpt_download.py', <http.client.HTTPMessage at 0x74608e026480>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T10:46:50.185893455Z",
     "start_time": "2026-01-17T10:31:56.995936648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=\"124M\", models_dir=\"gpt2\"\n",
    ")\n",
    "\n"
   ],
   "id": "e60217d41242c835",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checkpoint: 100%|| 77.0/77.0 [00:00<00:00, 193kiB/s]\n",
      "encoder.json: 100%|| 1.04M/1.04M [00:06<00:00, 172kiB/s] \n",
      "hparams.json: 100%|| 90.0/90.0 [00:00<00:00, 237kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|| 498M/498M [14:33<00:00, 570kiB/s]    \n",
      "model.ckpt.index: 100%|| 5.21k/5.21k [00:00<00:00, 5.51MiB/s]\n",
      "model.ckpt.meta: 100%|| 471k/471k [00:01<00:00, 368kiB/s]  \n",
      "vocab.bpe: 100%|| 456k/456k [00:01<00:00, 269kiB/s]  \n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T10:47:21.996107957Z",
     "start_time": "2026-01-17T10:47:21.952440558Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}"
   ],
   "id": "7458f3d4976c701c",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T10:47:23.777575103Z",
     "start_time": "2026-01-17T10:47:23.749779232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_name = \"gpt2-small (124M)\"\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "NEW_CONFIG.update({\"context_length\": 1024})\n",
    "NEW_CONFIG.update({\"qkv_bias\": True})"
   ],
   "id": "59ff06cddda31251",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T10:47:25.708202329Z",
     "start_time": "2026-01-17T10:47:24.971831126Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval()"
   ],
   "id": "e106a131065f358b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T10:47:28.620825259Z",
     "start_time": "2026-01-17T10:47:28.592765073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, \"\n",
    "            \"Right: {right.shape}\"\n",
    "        )\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ],
   "id": "daa9699a3cbd683",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T10:47:30.379316723Z",
     "start_time": "2026-01-17T10:47:30.352282347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params[\"wpe\"])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params[\"wte\"])\n",
    "\n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1\n",
    "        )\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T\n",
    "        )\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T\n",
    "        )\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T\n",
    "        )\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1\n",
    "        )\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b\n",
    "        )\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b\n",
    "        )\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b\n",
    "        )\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T\n",
    "        )\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"]\n",
    "        )\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T\n",
    "        )\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"]\n",
    "        )\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T\n",
    "        )\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"]\n",
    "        )\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"]\n",
    "        )\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"]\n",
    "        )\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"]\n",
    "        )\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"]\n",
    "        )\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n"
   ],
   "id": "8b1f432cde32a488",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "911b54c22335d0f6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T10:48:08.951921740Z",
     "start_time": "2026-01-17T10:48:08.814128587Z"
    }
   },
   "cell_type": "code",
   "source": [
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device)"
   ],
   "id": "235ad891b2dd9aa8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "afc68b988bf12583"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T10:49:12.993232421Z",
     "start_time": "2026-01-17T10:49:11.852261695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ],
   "id": "5447a2d8f7bc56cf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you toward finding an ideal new way to practice something!\n",
      "\n",
      "What makes us want to be on top of that?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 61
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
